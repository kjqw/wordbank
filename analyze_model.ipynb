{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "\n",
    "import utilities_latent as ul\n",
    "import utilities_plot as up\n",
    "from utilities_base import VAE, load_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みの重みとデータを読み込む\n",
    "\n",
    "data, data_id_dict, child_id_dict, word_dict, category_dict = load_data(\n",
    "    [\"data\", \"data_id_dict\", \"child_id_dict\", \"word_dict\", \"category_dict\"]\n",
    ")\n",
    "word_count = len(word_dict)\n",
    "\n",
    "model = VAE().to(\"cuda\")\n",
    "model.load_state_dict(torch.load(\"tmp/best_model.pth\"))\n",
    "# model.load_state_dict(torch.load(\"tmp/model_state_dict.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# カテゴリの表示\n",
    "for key, val in category_dict.items():\n",
    "    print(key, len(val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 学習済みモデルで実データを潜在空間に射影\n",
    "\n",
    "figs = {}\n",
    "figs[\"tmp\"] = plt.subplots()\n",
    "fig, ax = figs[\"tmp\"]\n",
    "up.plot_x(model, data, ax)\n",
    "ax.set_xlabel(\"z1\")\n",
    "ax.set_ylabel(\"z2\")\n",
    "fig.savefig(\"images/latent_space.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 年齢の実データと語彙の実データを潜在空間上にプロット\n",
    "\n",
    "figs[\"age\"] = plt.subplots()\n",
    "figs[\"vocabulary\"] = plt.subplots()\n",
    "\n",
    "data_ids = list(data_id_dict.keys())\n",
    "up.plot_x_with_age(model, data_ids, *figs[\"age\"])\n",
    "up.plot_x_with_vocabulary(model, data_ids, *figs[\"vocabulary\"], [\"all\"])\n",
    "# up.plot_x_with_vocabulary(\n",
    "#     model,\n",
    "#     data_ids,\n",
    "#     *figs[\"vocabulary\"],\n",
    "#     [上のセルの結果を参考にしてここに語彙のカテゴリを入れる([\"all\"]だと全語彙)]\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 潜在空間の語彙の発達具合をcategoryごとに可視化して保存\n",
    "\n",
    "z1_start, z1_end = -6, 7\n",
    "z2_start, z2_end = -3, 3\n",
    "spacing = 0.1\n",
    "\n",
    "z_meshgrid = up.make_lattice_points(z1_start, z1_end, z2_start, z2_end, spacing)\n",
    "for category in category_dict.keys():\n",
    "    figs[category] = plt.subplots()\n",
    "    up.plot_vocabulary(model, z_meshgrid, *figs[category], [category])\n",
    "    up.plot_x(model, data, figs[category][1], \"black\")\n",
    "    figs[category][0].savefig(f\"images/vocabulary/{category}_vocabulary.png\")\n",
    "    plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 潜在空間の語彙の発達具合を全categoryまとめて可視化して保存\n",
    "\n",
    "figs[\"all\"] = plt.subplots()\n",
    "up.plot_vocabulary(model, z_meshgrid, *figs[\"all\"], [\"all\"])\n",
    "up.plot_x(model, data, figs[\"all\"][1], \"black\")\n",
    "figs[\"all\"][0].savefig(f\"images/vocabulary/{\"all\"}_vocabulary.png\")\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 縦断データ(同じ子供の年齢が違うデータ)の可視化\n",
    "\n",
    "figs[\"arrow\"] = plt.subplots()\n",
    "up.plot_x(model, data, figs[\"arrow\"][1])\n",
    "data_ids = []\n",
    "\n",
    "# 何個以上の縦断データを選ぶか\n",
    "n = 2\n",
    "for i, v in child_id_dict.items():\n",
    "    if len(v) >= n:\n",
    "        data_ids.append([j[0] for j in v])\n",
    "# print(len(data_ids))\n",
    "\n",
    "# n個以上の縦断データの中からランダムにm個選んでプロット\n",
    "m = 20\n",
    "datas = random.sample(data_ids, m)\n",
    "child_id = data_id_dict[datas[0][0]][0]\n",
    "print(child_id_dict[child_id])\n",
    "for i in datas:\n",
    "    up.plot_arrow(model, i, figs[\"arrow\"][1])\n",
    "# figs[\"arrow\"][0].savefig(\"images/arrow.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 観察しやすそうな実データ\n",
    "\n",
    "# child_id: 3461, 3499, 2860\n",
    "tmp_data_id = 3499\n",
    "tmp_child_id = data_id_dict[tmp_data_id][0]\n",
    "# print(tmp_child_id)\n",
    "# print(child_id_dict[tmp_child_id])\n",
    "data_ids = [i[0] for i in child_id_dict[tmp_child_id]]\n",
    "print(data_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_data = up.child_id_to_data(tmp_child_id)\n",
    "tmp_z = up.x_to_z(model, tmp_data)\n",
    "point_O = tmp_z[1, :]\n",
    "point_A = tmp_z[2, :]\n",
    "point_P = tmp_z[3, :]\n",
    "\n",
    "# 直線OPに対してAと対称な点Bを求める\n",
    "point_B = ul.get_symmetric_points(point_O, point_P, point_A)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figs[\"tmp\"] = plt.subplots()\n",
    "fig, ax = figs[\"tmp\"]\n",
    "up.plot_x(model, data, ax)\n",
    "up.plot_arrow(model, data_ids, ax)\n",
    "points = {\"O\": point_O, \"A\": point_A, \"P\": point_P, \"B\": point_B}\n",
    "for i in points:\n",
    "    ax.scatter(points[i][0], points[i][1], color=\"tab:orange\")\n",
    "    ax.annotate(i, points[i], textcoords=\"offset points\", xytext=(0, 5), ha=\"center\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
